# Recommendation Engine - Dual Mode Setup

## üì¶ Modes

### 1. Docker Mode (Production/Host)
Ch·∫°y trong Docker, k·∫øt n·ªëi v·ªõi c√°c services qua **service names**:
- `vault:8200`
- `kafka:29092`
- `consul:8500`

### 2. Local Mode (Development/Testing)
Ch·∫°y tr·ª±c ti·∫øp tr√™n Mac, k·∫øt n·ªëi v·ªõi Docker services qua **localhost**:
- `localhost:8200`
- `localhost:9092`
- `localhost:8500`

---

## üöÄ Quick Start

### Docker Mode (Recommended for Production)

```bash
# Start everything (infrastructure + services)
./dev.sh full up

# Or start only recommendation-engine
docker-compose --profile services up recommendation-engine -d

# View logs
docker logs -f recommendation-engine

# Health check
curl http://localhost:8001/health
```

### Local Mode (Recommended for Development)

**Step 1: Start Infrastructure Services**
```bash
# Start only infrastructure (Vault, Kafka, MongoDB, PostgreSQL, etc.)
./dev.sh infra up
```

**Step 2: Run Recommendation Engine Locally**
```bash
cd services/recommendation-engine

# Run the script (auto-installs dependencies, checks services)
./run-local.sh
```

The script will:
- ‚úÖ Create Python virtual environment if needed
- ‚úÖ Install dependencies from `requirements.txt`
- ‚úÖ Check if Docker services (Vault, Kafka) are running
- ‚úÖ Load `.env.local` configuration
- ‚úÖ Start server with hot-reload on port 8000

**Access:**
- API: http://localhost:8000
- Health: http://localhost:8000/health
- Docs: http://localhost:8000/docs

---

## ‚öôÔ∏è Configuration Files

### `.env.local` (Local Mode)
Located at `services/recommendation-engine/.env.local`

Key differences from Docker:
```bash
# Vault: Docker service ‚Üí localhost
VAULT_ADDR=http://localhost:8200

# Kafka: Internal port ‚Üí external port
KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# Model path: Container path ‚Üí local path
MODEL_PATH=./models/bi-encoder-e5-large
FAISS_INDEX_PATH=./data/faiss_index
```

### `docker-compose.yml` (Docker Mode)
Recommendation engine service config:
```yaml
environment:
  - VAULT_ADDR=http://vault:8200
  - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
  - MODEL_PATH=/app/models/bi-encoder-e5-large
```

---

## üîÑ Switching Between Modes

### From Docker ‚Üí Local
```bash
# Stop Docker recommendation-engine
docker stop recommendation-engine

# Run locally
cd services/recommendation-engine
./run-local.sh
```

### From Local ‚Üí Docker
```bash
# Stop local process (Ctrl+C)

# Start Docker container
docker-compose --profile services up recommendation-engine -d
```

---

## üß™ Testing Both Modes

### Test Docker Mode
```bash
# Ensure running in Docker
docker ps | grep recommendation-engine

# Test endpoint
curl http://localhost:8001/health
```

### Test Local Mode
```bash
# Ensure running locally (check terminal with ./run-local.sh)

# Test endpoint
curl http://localhost:8000/health
```

### Test Job Service Integration
```bash
# Job Service connects to recommendation-engine
# Check application.yml: service.recommendation.url

# Docker mode: http://recommendation-engine:8000
# Local mode: http://localhost:8000 or http://localhost:8001
```

---

## üìä Port Mapping

| Mode | Port | URL | Notes |
|------|------|-----|-------|
| Docker | 8001 | http://localhost:8001 | Mapped from container :8000 |
| Local | 8000 | http://localhost:8000 | Direct on host |

**Tip:** Job Service can be configured to use either:
```yaml
# In job-service application.yml
service:
  recommendation:
    url: ${RECOMMENDATION_ENGINE_URL:http://localhost:8001}  # Docker
    # url: ${RECOMMENDATION_ENGINE_URL:http://localhost:8000}  # Local
```

---

## üõ†Ô∏è Troubleshooting

### Local Mode: "Connection Refused"
```bash
# Check if infrastructure is running
docker ps | grep -E "vault|kafka|consul"

# Start infrastructure
./dev.sh infra up

# Verify connectivity
curl http://localhost:8200/v1/sys/health  # Vault
```

### Local Mode: Model Not Found
```bash
# Check model directory
ls -la services/recommendation-engine/models/bi-encoder-e5-large

# Model will auto-download on first run if missing
# Or manually place model files in models/ directory
```

### Docker Mode: Out of Memory
```bash
# Increase Docker memory allocation in Docker Desktop
# Settings ‚Üí Resources ‚Üí Memory ‚Üí 8GB+

# Or run in Local mode to avoid Docker limits
./run-local.sh
```

### Port Conflict
```bash
# Local mode using 8000, Docker using 8001
# If port 8000 is busy, edit .env.local:
PORT=8002

# If Docker port 8001 is busy, edit docker-compose.yml:
ports:
  - "8003:8000"  # Change 8001 ‚Üí 8003
```

---

## üéØ Best Practices

### Use Docker Mode When:
- ‚úÖ Running full system integration tests
- ‚úÖ Deploying to production/staging
- ‚úÖ Other developers need consistent environment
- ‚úÖ CI/CD pipelines

### Use Local Mode When:
- ‚úÖ Developing ML features (model training, tuning)
- ‚úÖ Debugging Python code with breakpoints
- ‚úÖ Testing with large models (avoid Docker memory limits)
- ‚úÖ Fast iteration with hot-reload
- ‚úÖ Need direct access to model files

---

## üìù Development Workflow Example

```bash
# 1. Start infrastructure
./dev.sh infra up

# 2. Run recommendation-engine locally for development
cd services/recommendation-engine
./run-local.sh

# 3. Run job-service in Docker (or locally via IDE)
docker-compose up job-service -d

# 4. Make changes to Python code
# ‚Üí Uvicorn auto-reloads on file changes

# 5. Test integration
curl -X POST http://localhost:9082/public/recommendations/for-me \
  -H "Authorization: Bearer YOUR_TOKEN"

# 6. When done, stop local and start Docker
# Ctrl+C to stop local
docker-compose up recommendation-engine -d
```

---

## üîó Related Services Integration

### Job Service Configuration
Update `services/job-service/src/main/resources/application.yml`:

```yaml
service:
  recommendation:
    # Docker mode (recommendation-engine in Docker)
    url: ${RECOMMENDATION_ENGINE_URL:http://recommendation-engine:8000}
    
    # Local mode (recommendation-engine on host)
    # url: ${RECOMMENDATION_ENGINE_URL:http://host.docker.internal:8000}
```

**Note:** Use `host.docker.internal` to access host from Docker container

### Environment Variable Override
```bash
# When running job-service
export RECOMMENDATION_ENGINE_URL=http://localhost:8000  # For local
docker-compose up job-service
```

---

## ‚úÖ Verification Checklist

- [ ] Infrastructure services running: `docker ps`
- [ ] Vault accessible: `curl http://localhost:8200/v1/sys/health`
- [ ] Kafka accessible: `docker logs kafka-workfitai | tail`
- [ ] Model files exist: `ls services/recommendation-engine/models/`
- [ ] Python venv activated: `which python` shows `venv/bin/python`
- [ ] Dependencies installed: `pip list | grep sentence-transformers`
- [ ] Server running: `curl http://localhost:8000/health`
- [ ] FAISS index created: `ls services/recommendation-engine/data/faiss_index/`
